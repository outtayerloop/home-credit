{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "colab": {
   "name": "temp.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "1a069376-2802-477e-ae22-8192da45be11"
   },
   "source": [
    "# Data preprocessing"
   ],
   "id": "1a069376-2802-477e-ae22-8192da45be11"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "J44Q8wLcBs7W"
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "id": "J44Q8wLcBs7W",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYngGJuJABAl"
   },
   "source": [
    "## Obtaining base train and test dataframes"
   ],
   "id": "oYngGJuJABAl"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    },
    "id": "39d2ae9c-7e40-4baa-9c72-cdd5d912bb04"
   },
   "source": [
    "### Creating train and test dataframes"
   ],
   "id": "39d2ae9c-7e40-4baa-9c72-cdd5d912bb04"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iFDLQubNVQtP"
   },
   "source": [
    "def get_dataframes():\n",
    "  \"\"\"Return a tuple containing train and test dataframes.\"\"\"\n",
    "  train = pd.read_csv('./data/external/application_train.csv')\n",
    "  test = pd.read_csv('./data/external/application_test.csv')\n",
    "  return train, test"
   ],
   "id": "iFDLQubNVQtP",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Oec65GiJ3Tp"
   },
   "source": [
    "### Moving target to last column in train dataset"
   ],
   "id": "0Oec65GiJ3Tp"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Gn1N4tAZJ6xn"
   },
   "source": [
    "def position_target_column(train):\n",
    "  \"\"\"Return train dataframe with target as last column.\n",
    "\n",
    "  Keyword arguments:\n",
    "  train -- the train dataframe\n",
    "  \"\"\"\n",
    "  target_col = train.pop('TARGET')\n",
    "  train['TARGET'] = target_col\n",
    "  return train"
   ],
   "id": "Gn1N4tAZJ6xn",
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPF5c_yEHrGg"
   },
   "source": [
    "### Dropping unused ID column"
   ],
   "id": "zPF5c_yEHrGg"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tSqMlcE7Hu75"
   },
   "source": [
    "def drop_id_column(train, test):\n",
    "  \"\"\"Return a tuple containing train and test dataframes without id column.\n",
    "\n",
    "  Keyword arguments:\n",
    "  train -- the train dataframe\n",
    "  test -- the test dataframe\n",
    "  \"\"\"\n",
    "  train = train.drop(['SK_ID_CURR'], axis=1)\n",
    "  test = test.drop(['SK_ID_CURR'], axis=1)\n",
    "  return train, test"
   ],
   "id": "tSqMlcE7Hu75",
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3iz2_FRjk4u"
   },
   "source": [
    "### Organizing test set columns based on train set column order"
   ],
   "id": "x3iz2_FRjk4u"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oWUncy_bjzSu"
   },
   "source": [
    "def reorder_test_columns(train, test):\n",
    "  \"\"\"Return test dataframe with columns organized following train dataframe columns order.\n",
    "\n",
    "  Keyword arguments:\n",
    "  train -- the train dataframe\n",
    "  test -- the test dataframe\n",
    "  \"\"\"\n",
    "  test = test[train.drop(['TARGET'], axis=1).columns]\n",
    "  return test"
   ],
   "id": "oWUncy_bjzSu",
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUGqhOrkF7VX"
   },
   "source": [
    "## Taking care of missing data"
   ],
   "id": "RUGqhOrkF7VX"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "m7aKDXPjF-C3"
   },
   "source": [
    "def impute_train_missing_data(train):\n",
    "  \"\"\"\n",
    "  Return tuple containing train dataframe with median imputed in place of missing numerical values \n",
    "  and a Series with its numerical columns.\n",
    "\n",
    "  Keyword arguments:\n",
    "  train -- the train dataframe\n",
    "  \"\"\"\n",
    "  imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "  x_dtypes_train = train.dtypes[:-1]\n",
    "  num_cols_train = x_dtypes_train == np.number\n",
    "  X_train = train.iloc[:, :-1].values\n",
    "  imputer.fit(X_train[:, num_cols_train])\n",
    "  X_train[:, num_cols_train] = imputer.transform(X_train[:, num_cols_train])\n",
    "  train.iloc[:, :-1] = X_train\n",
    "  return train, num_cols_train"
   ],
   "id": "m7aKDXPjF-C3",
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bgQxbY5Mjef1"
   },
   "source": [
    "def impute_test_missing_data(test):\n",
    "  \"\"\"\n",
    "  Return tuple containing test dataframe with median imputed in place of missing numerical values \n",
    "  and a Series with its numerical columns.\n",
    "\n",
    "    Keyword arguments:\n",
    "    test -- the test dataframe\n",
    "    \"\"\"\n",
    "  imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "  x_dtypes_test = test.dtypes\n",
    "  num_cols_test = x_dtypes_test == np.number\n",
    "  X_test = test.iloc[:, :].values\n",
    "  imputer.fit(X_test[:, num_cols_test])\n",
    "  X_test[:, num_cols_test] = imputer.transform(X_test[:, num_cols_test])\n",
    "  test.iloc[:, :] = X_test\n",
    "  return test, num_cols_test"
   ],
   "id": "bgQxbY5Mjef1",
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAvaeTqpRlxf"
   },
   "source": [
    "### Get text features Na rows percentage"
   ],
   "id": "hAvaeTqpRlxf"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9LuAtXAyO4sQ"
   },
   "source": [
    "def get_train_na_percentages(train):\n",
    "  \"\"\"\n",
    "  Return a Series with the percentage of Na values per columns in train dataframe.\n",
    "  Must be called just after impute_train_missing_data().\n",
    "\n",
    "  Keyword arguments:\n",
    "  train -- the train dataframe\n",
    "  \"\"\"\n",
    "  na_cols_pctg_train = train[train.columns[train.isna().sum() > 0]].isna().sum() / train.shape[0]\n",
    "  return na_cols_pctg_train"
   ],
   "id": "9LuAtXAyO4sQ",
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFdGMgFhRt8R"
   },
   "source": [
    "### Drop text features Na rows"
   ],
   "id": "wFdGMgFhRt8R"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nxIcZ8luRwAC"
   },
   "source": [
    "def drop_textual_feat_na_rows(train, test):\n",
    "  \"\"\"Return a tuple containing train and test dataframes without textual features Na rows.\n",
    "\n",
    "  Keyword arguments:\n",
    "  train -- the train dataframe\n",
    "  test -- the test dataframe\n",
    "  \"\"\"\n",
    "  train = train.dropna(axis=0)\n",
    "  test = test.dropna(axis=0)\n",
    "  return train, test"
   ],
   "id": "nxIcZ8luRwAC",
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9hpg1ZXAxEn"
   },
   "source": [
    "## Encoding categorical data"
   ],
   "id": "w9hpg1ZXAxEn"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtbCfv0RBzMe"
   },
   "source": [
    "### Encoding the independent variables"
   ],
   "id": "mtbCfv0RBzMe"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jhSb0ulEDB3f"
   },
   "source": [
    "def get_textual_column_indexes(train, test):\n",
    "  \"\"\"Return a tuple containing an ndarray with train and test textual column indexes.\n",
    "\n",
    "  Keyword arguments:\n",
    "  train -- the train dataframe\n",
    "  test -- the test dataframe\n",
    "  \"\"\"\n",
    "  txt_cols_train = train.select_dtypes('object').columns\n",
    "  txt_indexes_train = train.columns.get_indexer(txt_cols_train)\n",
    "  txt_cols_test = test.select_dtypes('object').columns\n",
    "  txt_indexes_test = test.columns.get_indexer(txt_cols_test)\n",
    "  return txt_cols_train, txt_indexes_test"
   ],
   "id": "jhSb0ulEDB3f",
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7K1WiR32BmU2"
   },
   "source": [
    "def label_encode_train(train, txt_indexes_train):\n",
    "  \"\"\"Return the train dataframe with label-encoded textual features.\n",
    "\n",
    "  Keyword arguments:\n",
    "  train -- the train dataframe\n",
    "  txt_indexes_train -- ndarray of train textual column indexes\n",
    "  \"\"\"\n",
    "  label_encoder_x = LabelEncoder()\n",
    "  X_train = train.iloc[:, :-1].values\n",
    "  for i in txt_indexes_train:\n",
    "    X_train[:, i] = label_encoder_x.fit_transform(X_train[:, i])\n",
    "  train.iloc[:, :-1] = X_train\n",
    "  return train"
   ],
   "id": "7K1WiR32BmU2",
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GpYM3xmVkz3j"
   },
   "source": [
    "def label_encode_test(test, txt_indexes_test):\n",
    "  \"\"\"Return the test dataframe with label-encoded textual features.\n",
    "\n",
    "  Keyword arguments:\n",
    "  test -- the test dataframe\n",
    "  txt_indexes_test -- ndarray of test textual column indexes\n",
    "  \"\"\"\n",
    "  label_encoder_x = LabelEncoder()\n",
    "  X_test = test.iloc[:, :].values\n",
    "  for i in txt_indexes_test:\n",
    "    X_test[:, i] = label_encoder_x.fit_transform(X_test[:, i])\n",
    "  test.iloc[:, :] = X_test\n",
    "  return test"
   ],
   "id": "GpYM3xmVkz3j",
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eUpCP9FC42fJ"
   },
   "source": [
    "def label_encode_dataframes(train, test, txt_indexes_train, txt_indexes_test):\n",
    "  \"\"\"Return a tuple containing label-encoded train and test dataframes.\n",
    "\n",
    "  Keyword arguments:\n",
    "  train -- the train dataframe\n",
    "  test -- the test dataframe\n",
    "  txt_indexes_train -- ndarray of train textual column indexes\n",
    "  txt_indexes_test -- ndarray of test textual column indexes\n",
    "  \"\"\"\n",
    "  train = label_encode_train(train, txt_indexes_train)\n",
    "  test = label_encode_test(test, txt_indexes_test)\n",
    "  return train, test"
   ],
   "id": "eUpCP9FC42fJ",
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_yhicg4hlkl"
   },
   "source": [
    "## Feature scaling"
   ],
   "id": "x_yhicg4hlkl"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Mym1cklwhoAT"
   },
   "source": [
    "def standardize_train(train, num_cols_train):\n",
    "  \"\"\"Return the train dataframe with standardized numerical features (not the encoded textual dimensions).\n",
    "\n",
    "  Keyword arguments:\n",
    "  train -- the train dataframe\n",
    "  \"\"\"\n",
    "  sc = StandardScaler()\n",
    "  X_train = train.iloc[:, :-1].values\n",
    "  X_train[:, num_cols_train] = sc.fit_transform(X_train[:, num_cols_train])\n",
    "  train.iloc[:, :-1] = X_train\n",
    "  return train"
   ],
   "id": "Mym1cklwhoAT",
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lLoMGwhnlvD5"
   },
   "source": [
    "def standardize_test(test, num_cols_test):\n",
    "  \"\"\"Return the test dataframe with standardized numerical features (not the encoded textual dimensions).\n",
    "\n",
    "  Keyword arguments:\n",
    "  test -- the test dataframe\n",
    "  \"\"\"\n",
    "  sc = StandardScaler() # standardization implies values between approximately -3 and 3\n",
    "  X_test = test.iloc[:, :].values\n",
    "  X_test[:, num_cols_test] = sc.fit_transform(X_test[:, num_cols_test]) # we don't standardize encoded textual dimensions.\n",
    "  test.iloc[:, :] = X_test\n",
    "  return test"
   ],
   "id": "lLoMGwhnlvD5",
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "To5vZ44roDjL"
   },
   "source": [
    "## Feature selection"
   ],
   "id": "To5vZ44roDjL"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6PwqzS3L6fp"
   },
   "source": [
    "### Removing features with at least 50% Na values (percentage computed from train set)"
   ],
   "id": "E6PwqzS3L6fp"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pDC6VeFGMAbZ"
   },
   "source": [
    "def select_features_on_na(train, test, na_cols_pctg_train):\n",
    "  \"\"\"Return a tuple containing train and test dataframes without columns containing at least 50% Na values.\n",
    "\n",
    "  Keyword arguments:\n",
    "  train -- the train dataframe\n",
    "  test -- the test dataframe\n",
    "  na_cols_pctg_train -- a Series with the percentage of Na values per columns in train dataframe.\n",
    "  \"\"\"\n",
    "  dropped_cols = na_cols_pctg_train[na_cols_pctg_train >= 0.5].axes[0].tolist()\n",
    "  train = train.drop(dropped_cols, axis=1)\n",
    "  test = test.drop(dropped_cols, axis=1)\n",
    "  return train, test"
   ],
   "id": "pDC6VeFGMAbZ",
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YocDxkHkQUZh"
   },
   "source": [
    "### Removing features with a modality that appears with a probability of at least 80%"
   ],
   "id": "YocDxkHkQUZh"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vYuZbotJQXsJ"
   },
   "source": [
    "def select_features_on_mod_proba(train, test):\n",
    "  \"\"\"Return a tuple containing train and test dataframes \n",
    "  without columns containing modalities that appeared with a probability of at least 80%.\n",
    "\n",
    "  Keyword arguments:\n",
    "  train -- the train dataframe\n",
    "  test -- the test dataframe\n",
    "  \"\"\"\n",
    "  PROBABILITY_THRESHOLD = 0.8\n",
    "  train_without_target = train.drop('TARGET', axis=1)\n",
    "  cols_train = train_without_target.columns.tolist()\n",
    "  cols_to_drop_train = []\n",
    "  for col in cols_train:\n",
    "    mods_pctg = train_without_target[col].value_counts() / train_without_target[col].value_counts().sum()\n",
    "    for pctg in mods_pctg:\n",
    "      if pctg >= PROBABILITY_THRESHOLD:\n",
    "        cols_to_drop_train.append(col)\n",
    "  train = train.drop(cols_to_drop_train, axis=1)\n",
    "  test = test.drop(cols_to_drop_train, axis=1)\n",
    "  return train, test"
   ],
   "id": "vYuZbotJQXsJ",
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ag0L1nB6UsZ"
   },
   "source": [
    "## Preprocessed data export to CSV"
   ],
   "id": "-ag0L1nB6UsZ"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "G2iGO7OO6X65"
   },
   "source": [
    "def export_dataframes_to_csv_files(train, test):\n",
    "  \"\"\"Export train and test dataframes to CSV files to ./data/processed path.\n",
    "\n",
    "  Keyword arguments:\n",
    "  train -- the train dataframe\n",
    "  test -- the test dataframe\n",
    "  \"\"\"\n",
    "  train.to_csv('./data/processed/processed_application_train.csv', index=False)\n",
    "  test.to_csv('./data/processed/processed_application_test.csv', index=False)"
   ],
   "id": "G2iGO7OO6X65",
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oELQf611CPH7"
   },
   "source": [
    "## Executing the preprocessing workflow"
   ],
   "id": "oELQf611CPH7"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TCTVgKVsCVsR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def get_features():\n",
    "  (train, test) = get_dataframes()\n",
    "  train = position_target_column(train)\n",
    "  (train, test) = drop_id_column(train, test)\n",
    "  test = reorder_test_columns(train, test)\n",
    "  (train, num_cols_train) = impute_train_missing_data(train)\n",
    "  (test, num_cols_test) = impute_test_missing_data(test)\n",
    "  na_cols_pctg_train = get_train_na_percentages(train)\n",
    "  (train, test) = drop_textual_feat_na_rows(train, test)\n",
    "  txt_indexes_train, txt_indexes_test = get_textual_column_indexes(train, test)\n",
    "  (train, test) = label_encode_dataframes(train, test, txt_indexes_train, txt_indexes_test)\n",
    "  train = standardize_train(train, num_cols_train)\n",
    "  test = standardize_test(test, num_cols_test)\n",
    "  (train, test) = select_features_on_na(train, test, na_cols_pctg_train)\n",
    "  (train, test) = select_features_on_mod_proba(train, test)\n",
    "  export_dataframes_to_csv_files(train, test)"
   ],
   "id": "TCTVgKVsCVsR",
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_features()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}