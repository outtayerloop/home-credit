{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import logging\n",
    "import mlflow\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_split_train_data():\n",
    "  \"\"\"Return a tuple containing split train data into X_train X_test, y_train and y_test.\"\"\"\n",
    "  df = pd.read_csv('../../data/processed/processed_application_train.csv')\n",
    "  train, test = train_test_split(df)\n",
    "  X_train = train.drop(['TARGET'], axis=1)\n",
    "  X_test = test.drop(['TARGET'], axis=1)\n",
    "  y_train = train[['TARGET']]\n",
    "  y_test = test[['TARGET']]\n",
    "  return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding MLFLow workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_configured_logger():\n",
    "  \"\"\"Return a logger for console outputs configured to print warnings.\"\"\"\n",
    "  logging.basicConfig(level=logging.WARN)\n",
    "  return logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model on split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_random_forest_classifier(X_train, y_train):\n",
    "  \"\"\"Return RandomForestClassifier fit on input ndarrays X_train and y_train.\n",
    "\n",
    "  Keyword arguments:\n",
    "  X_train -- ndarray containing all train columns except target column\n",
    "  y_train -- ndarray target column values to train the model\n",
    "  \"\"\"\n",
    "  clf = RandomForestClassifier(class_weight='balanced', n_estimators=100, n_jobs=-1)\n",
    "  gs = GridSearchCV(clf, {'model__max_depth': [10, 15], 'model__min_samples_split': [5, 10]}, n_jobs=-1, cv=5, scoring='accuracy')\n",
    "  gs.fit(X_train.values, y_train.values)\n",
    "  clf.set_params(**gs.best_params_)\n",
    "  clf = clf.fit(X_train, y_train)\n",
    "  return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting model evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "  \"\"\"Return a tuple containing model classification accuracy, confusion matrix and f1_score.\n",
    "\n",
    "  Keyword arguments:\n",
    "  actual -- ndarray y_test containing true target values\n",
    "  pred -- ndarray of the predicted target values by the model\n",
    "  \"\"\"\n",
    "  accuracy = accuracy_score(actual, pred)\n",
    "  conf_matrix = confusion_matrix(actual, pred)\n",
    "  f_score = f1_score(actual, pred)\n",
    "  return accuracy, conf_matrix, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_evaluation_metrics(clf, X_test, y_test):\n",
    "  \"\"\"Return a tuple containing model classification accuracy, confusion matrix, f1_score and ROC area under the curve score.\n",
    "\n",
    "  Keyword arguments:\n",
    "  clf -- classifier model\n",
    "  X_test -- ndarray containing all test columns except target column\n",
    "  y_test -- ndarray target column values to test the model\n",
    "  \"\"\"\n",
    "  predicted_repayments = clf.predict(X_test)\n",
    "  (accuracy, conf_matrix, f_score) = eval_metrics(y_test, predicted_repayments)\n",
    "  rf_probs = clf.predict_proba(X_test)\n",
    "  rf_probs = rf_probs[:, 0]  # keeping only the first class (repayment OK)\n",
    "  rf_roc_auc_score = roc_auc_score(y_test, rf_probs)\n",
    "  random_probs = [0 for _ in range(len(y_test))]\n",
    "  random_roc_auc_score = roc_auc_score(y_test, random_probs)\n",
    "  return accuracy, conf_matrix, f_score, rf_roc_auc_score, random_roc_auc_score, rf_probs, random_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking model on MLFLow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def track_model_params(clf):\n",
    "  \"\"\"Log model params on MLFlow UI.\n",
    "\n",
    "  Keyword arguments:\n",
    "  clf -- classifier model\n",
    "  \"\"\"\n",
    "  clf_params = clf.get_params()\n",
    "  for param in clf_params:\n",
    "      param_value = clf_params[param]\n",
    "      mlflow.log_param(param, param_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualizing ROC AUC scores summaries for both Random Forest and Random model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def vizualize_roc_curves(rf_roc_auc_score, random_roc_auc_score, y_test, rf_probs, random_probs):\n",
    "  \"\"\"Vizualize ROC curves for both fit model and random model.\n",
    "\n",
    "  Keyword arguments:\n",
    "  rf_roc_auc_score -- fit model ROC AUC score\n",
    "  random_roc_auc_score -- random model ROC AUC score\n",
    "  y_test -- ndarray of target values\n",
    "  rf_probs -- fit model predicted probabilities\n",
    "  random_probs -- random model predicted probabilities\n",
    "  \"\"\"\n",
    "  # summarize scores\n",
    "  print('Random model: ROC AUC=%.3f' % random_roc_auc_score)\n",
    "  print('Random Forest: ROC AUC=%.3f' % rf_roc_auc_score)\n",
    "  # calculate roc curves\n",
    "  random_fpr, random_tpr, _ = roc_curve(y_test, random_probs)\n",
    "  rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)\n",
    "  # plot the roc curve for the model\n",
    "  pyplot.plot(random_fpr, random_tpr, linestyle='--', label='Random model')\n",
    "  pyplot.plot(rf_fpr, rf_tpr, marker='.', label='Random Forest')\n",
    "  # axis labels\n",
    "  pyplot.xlabel('False Positive Rate')\n",
    "  pyplot.ylabel('True Positive Rate')\n",
    "  # show the legend\n",
    "  pyplot.legend()\n",
    "  # show the plot\n",
    "  pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def track_model_metrics(clf, X_test, y_test):\n",
    "  \"\"\"Log model metrics on MLFlow UI.\n",
    "\n",
    "  Keyword arguments:\n",
    "  clf -- classifier model\n",
    "  X_test -- ndarray containing all test columns except target column\n",
    "  y_test -- ndarray target column values to test the model\n",
    "  \"\"\"\n",
    "  (accuracy, conf_matrix, f_score, rf_roc_auc_score, random_roc_auc_score, rf_probs, random_probs) = \\\n",
    "    get_model_evaluation_metrics(clf, X_test, y_test)\n",
    "  mlflow.log_metric('accuracy', accuracy)\n",
    "  mlflow.log_metric('f1_score', f_score)\n",
    "  mlflow.log_metric('roc_auc_score', rf_roc_auc_score)\n",
    "  vizualize_roc_curves(rf_roc_auc_score, random_roc_auc_score, y_test, rf_probs, random_probs)\n",
    "  #mlflow.log_metric('conf_matrix', conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def track_model_version(clf):\n",
    "  \"\"\"Version model on MLFlow UI.\n",
    "\n",
    "  Keyword arguments:\n",
    "  clf -- classifier model\n",
    "  \"\"\"\n",
    "  tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "  if tracking_url_type_store != 'file':\n",
    "      mlflow.sklearn.log_model(clf, 'model', registered_model_name='RandomForestClassifier')\n",
    "  else:\n",
    "      mlflow.sklearn.log_model(clf, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def set_mlflow_run_tags():\n",
    "  \"\"\"Set current MLFlow run tags.\"\"\"\n",
    "  tags = {'model_name': 'RandomForestClassifier'}\n",
    "  mlflow.set_tags(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_track_model_in_mlflow():\n",
    "  \"\"\"Train model and track it with MLFLow\"\"\"\n",
    "  (X_train, X_test, y_train, y_test) = get_split_train_data()\n",
    "  logger = get_configured_logger()\n",
    "  clf = train_random_forest_classifier(X_train, y_train)\n",
    "  with mlflow.start_run():\n",
    "    track_model_params(clf)\n",
    "    track_model_metrics(clf, X_test, y_test)\n",
    "    track_model_version(clf)\n",
    "    set_mlflow_run_tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter model for estimator RandomForestClassifier(class_weight='balanced', n_jobs=-1). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31m_RemoteTraceback\u001B[0m                          Traceback (most recent call last)",
      "\u001B[1;31m_RemoteTraceback\u001B[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\users\\wiemc\\documents\\applications_of_big_data\\home-credit\\venv\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 436, in _process_worker\n    r = call_item()\n  File \"c:\\users\\wiemc\\documents\\applications_of_big_data\\home-credit\\venv\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 288, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"c:\\users\\wiemc\\documents\\applications_of_big_data\\home-credit\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\users\\wiemc\\documents\\applications_of_big_data\\home-credit\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"c:\\users\\wiemc\\documents\\applications_of_big_data\\home-credit\\venv\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"c:\\users\\wiemc\\documents\\applications_of_big_data\\home-credit\\venv\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 211, in __call__\n    return self.function(*args, **kwargs)\n  File \"c:\\users\\wiemc\\documents\\applications_of_big_data\\home-credit\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 669, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"c:\\users\\wiemc\\documents\\applications_of_big_data\\home-credit\\venv\\lib\\site-packages\\sklearn\\base.py\", line 240, in set_params\n    raise ValueError(\nValueError: Invalid parameter model for estimator RandomForestClassifier(class_weight='balanced', n_jobs=-1). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_19460/1714906232.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mtrain_and_track_model_in_mlflow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_19460/1071256274.py\u001B[0m in \u001B[0;36mtrain_and_track_model_in_mlflow\u001B[1;34m()\u001B[0m\n\u001B[0;32m      3\u001B[0m   \u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_split_train_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m   \u001B[0mlogger\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_configured_logger\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m   \u001B[0mclf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain_random_forest_classifier\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m   \u001B[1;32mwith\u001B[0m \u001B[0mmlflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstart_run\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[0mtrack_model_params\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_19460/3194186554.py\u001B[0m in \u001B[0;36mtrain_random_forest_classifier\u001B[1;34m(X_train, y_train)\u001B[0m\n\u001B[0;32m      8\u001B[0m   \u001B[0mclf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mRandomForestClassifier\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclass_weight\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'balanced'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_estimators\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m100\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m   \u001B[0mgs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mGridSearchCV\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;34m'model__max_depth'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m15\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'model__min_samples_split'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m10\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcv\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscoring\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'accuracy'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m   \u001B[0mgs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m   \u001B[0mclf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mset_params\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mgs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbest_params_\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m   \u001B[0mclf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mclf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\wiemc\\documents\\applications_of_big_data\\home-credit\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    889\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mresults\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    890\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 891\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_run_search\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    892\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    893\u001B[0m             \u001B[1;31m# multimetric is determined here because in the case of a callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\wiemc\\documents\\applications_of_big_data\\home-credit\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36m_run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1390\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_run_search\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1391\u001B[0m         \u001B[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1392\u001B[1;33m         \u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mParameterGrid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparam_grid\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1393\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1394\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\wiemc\\documents\\applications_of_big_data\\home-credit\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36mevaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    836\u001B[0m                     )\n\u001B[0;32m    837\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 838\u001B[1;33m                 out = parallel(\n\u001B[0m\u001B[0;32m    839\u001B[0m                     delayed(_fit_and_score)(\n\u001B[0;32m    840\u001B[0m                         \u001B[0mclone\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbase_estimator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\wiemc\\documents\\applications_of_big_data\\home-credit\\venv\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1054\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1055\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mretrieval_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1056\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mretrieve\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1057\u001B[0m             \u001B[1;31m# Make sure that we get a last message telling us we are done\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1058\u001B[0m             \u001B[0melapsed_time\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_start_time\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\wiemc\\documents\\applications_of_big_data\\home-credit\\venv\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36mretrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    933\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    934\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'supports_timeout'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 935\u001B[1;33m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    936\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    937\u001B[0m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\wiemc\\documents\\applications_of_big_data\\home-credit\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36mwrap_future_result\u001B[1;34m(future, timeout)\u001B[0m\n\u001B[0;32m    540\u001B[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001B[0;32m    541\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 542\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfuture\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    543\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mCfTimeoutError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    544\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mTimeoutError\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\_base.py\u001B[0m in \u001B[0;36mresult\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    438\u001B[0m                 \u001B[1;32mraise\u001B[0m \u001B[0mCancelledError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    439\u001B[0m             \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_state\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0mFINISHED\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 440\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__get_result\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    441\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    442\u001B[0m                 \u001B[1;32mraise\u001B[0m \u001B[0mTimeoutError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\_base.py\u001B[0m in \u001B[0;36m__get_result\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    387\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__get_result\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    388\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_exception\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 389\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_exception\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    390\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    391\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_result\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Invalid parameter model for estimator RandomForestClassifier(class_weight='balanced', n_jobs=-1). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "train_and_track_model_in_mlflow()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}